{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishit605/Deep-Learning/blob/main/Tensor_Keras_Training_Custom_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WKtOUzvgW9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64bd40b3-b49b-4145-f980-b8a05ec00b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "## This method is used for connecting Google Drive to this Noebook and Access the Drive data.\n",
        "## This is a Code Snippet I had found on a python file from the internet.\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/Precision Agriculture/Task1 Team-4\" ## 'cd' stands for Change Directory and can be used for changing directory, Use this function and change the file path, put the file path after cd."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_WNblI1GQlN",
        "outputId": "a2faafdc-5336-4899-d581-9ea61f153185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Precision Agriculture/Task1 Team-4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # This is used for printing out what is the current directory we are in."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "irzsowjoGhIM",
        "outputId": "ee0aba14-86c6-4ab6-8e6a-6cb67b837a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Precision Agriculture/Task1 Team-4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## This function is Google Colab specific and is used to unzip a zip or rar file and '-d' defines the destination directory to which you need to extract the files to.\n",
        "\n",
        "# ! unzip '/content/drive/MyDrive/Precision Agriculture/Task1/dataset.zip' -d '/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data/dataset'"
      ],
      "metadata": {
        "id": "fImJWurWG1-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing Libraries\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "25GrvvOpHGMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the path to the images.\n",
        "\n",
        "dat = \"/content/drive/MyDrive/Precision Agriculture/Task1 Team-4/dataset/dataset/PlantVillage\""
      ],
      "metadata": {
        "id": "dJoFwarlnTz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function used for Checking the Total No. of files\n",
        "\n",
        "def file_list(dir):\n",
        "  files_list = [f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]\n",
        "  total_files = len(files_list)\n",
        "  return total_files"
      ],
      "metadata": {
        "id": "q_F2gkB_rKEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list('/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data/dataset/filtered_data/Applq')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnvDY6-Yr5y2",
        "outputId": "b4e2312e-d418-4602-bd5c-6b3e601b2190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RFYpiaXrsvAP",
        "outputId": "7e1b4109-a76e-4403-f288-dafbbe360ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Filtering the RGBA formate images\n",
        "## This comes under data manipulation>data Filtering \n",
        "## This function is used to filter and save RGB images to a different directory and custom function that I created. And can be used for a new dataset.\n",
        "\n",
        "filt = []\n",
        "\n",
        "def a_filt(src_path, img_size, tar_path):\n",
        "    for f in os.listdir(src_path):\n",
        "        if f.endswith(\".png\") or f.endswith(\".PNG\") or f.endswith(\".jpg\") or f.endswith(\".jpeg\"):\n",
        "            im = Image.open(os.path.join(src_path, f))\n",
        "            if im.mode == \"RGBA\":\n",
        "                print(f\"{f} has an alpha channel.\")\n",
        "                filt.append(f)\n",
        "            with Image.open(f'{src_path}/{f}') as img:\n",
        "                img_con = img.convert(\"RGB\")\n",
        "                img_a = img_con.resize((img_size))\n",
        "                img_a.save(f'{tar_path}/{f}')\n",
        "            if im.mode == \"RGB\":\n",
        "                print(\"0\")\n",
        "                img = img.resize((img_size))\n",
        "                img.save(f'{tar_path}/{f}')\n",
        "    print('\\nTotal Number of Files: ' , len(filt))"
      ],
      "metadata": {
        "id": "jxQq8QI_sBjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_filt(\"/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data/dataset/dataset/orange\", (224, 224), '/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data/dataset/filtered_data/Orange')"
      ],
      "metadata": {
        "id": "hn6YI37ltQnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "orange has 10 alpha\n",
        "apple has 14 aplha \n",
        "banana has 21 aplha\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_6COlcBeuEvV",
        "outputId": "c1f7cfd4-6739-46c7-9ac6-07d16bb270e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\norange has 10 alpha\\napple has 14 aplha \\nbanana has 21 aplha\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PARAMETERS\n",
        "## These varaibles define \n",
        "\n",
        "BATCH_SIZE=64\n",
        "IMG_SIZE=(150, 150)"
      ],
      "metadata": {
        "id": "FqiCCK1_w9UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filt_dat = '/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data/dataset/filtered_data-150 (custom CNN)'"
      ],
      "metadata": {
        "id": "lqWL1W9209sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## THis is an Import function that is provided by the Tensorflow/keras library.\n",
        "## It automatically load and mainpulate images without the need to save the maipulated images on the disk,\n",
        "## and automatically determines the classes, assuming that the images are speperated into different folder for classification.\n",
        "\n",
        "datagen = IDG( # These argumensts are used for Image Manipulation. And are not neccessay AT THE MOMENT but are very useful.\n",
        "    rescale=1./255, \n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    filt_dat,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical' ## This function defines the type of classifciation two arguments can be given are 'categorical' - for multiclass classification (more than 2) and 'binary' - for binary classification or classifying two classes.\n",
        ")\n",
        "\n",
        "# for i in range(10):\n",
        "# batch = train_gen.next()\n",
        "# print(batch[1])"
      ],
      "metadata": {
        "id": "2Y67CXd6u1Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is a convolutional Neural Network.\n",
        "## You can learn about it from ChatGPT by asking \"Explain the architecture of a CNN for Image Classification with code.\"\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)), ## This is an input layer. \n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'), ## This is a Convolution Layers 2D defines height and width of an image, 1D is used in texts, 3D is used for 3D images and photogrammetry.\n",
        "    layers.MaxPooling2D(pool_size=(2,2)), ## This is a Pooling layer, whihc essentially uses the pool_size argument to look at 4 pxiels for (2,2) and take their ax value and map it to lower dimenational image.\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'), ## This is a neuron fully_connected layer\n",
        "    layers.Dense(3, activation='softmax'), ## This is the output layer\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywGJImzkvhYO",
        "outputId": "dad6c135-7efe-448d-e5cf-596faafaeafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 73984)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               9470080   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,499,107\n",
            "Trainable params: 9,499,107\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Then we compile the model speperately as compatred to ML algorithms and specify our needs for the model to consider.\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=1e-3) ## This is fuction for defining custom Learning Rate and not neccessary for now. \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy']) ## 'loss' is defined by the use for multiclass classification or binary classification"
      ],
      "metadata": {
        "id": "aknsKQnCwaRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_gen, epochs=25, steps_per_epoch=train_gen.samples//BATCH_SIZE, verbose=1) ## Training the mode take splace here."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf1eMkkqwy-F",
        "outputId": "380c3982-d51f-41ce-c803-3d424db1aae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "3/3 [==============================] - 3s 353ms/step - loss: 0.6593 - accuracy: 0.7628\n",
            "Epoch 2/25\n",
            "3/3 [==============================] - 1s 441ms/step - loss: 0.5263 - accuracy: 0.8229\n",
            "Epoch 3/25\n",
            "3/3 [==============================] - 1s 432ms/step - loss: 0.4637 - accuracy: 0.8646\n",
            "Epoch 4/25\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.3770 - accuracy: 0.9038\n",
            "Epoch 5/25\n",
            "3/3 [==============================] - 1s 480ms/step - loss: 0.2891 - accuracy: 0.8910\n",
            "Epoch 6/25\n",
            "3/3 [==============================] - 1s 582ms/step - loss: 0.3367 - accuracy: 0.9038\n",
            "Epoch 7/25\n",
            "3/3 [==============================] - 2s 428ms/step - loss: 0.2654 - accuracy: 0.9103\n",
            "Epoch 8/25\n",
            "3/3 [==============================] - 1s 437ms/step - loss: 0.2617 - accuracy: 0.9115\n",
            "Epoch 9/25\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.1965 - accuracy: 0.9423\n",
            "Epoch 10/25\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.2221 - accuracy: 0.9167\n",
            "Epoch 11/25\n",
            "3/3 [==============================] - 1s 443ms/step - loss: 0.1643 - accuracy: 0.9427\n",
            "Epoch 12/25\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 0.1434 - accuracy: 0.9615\n",
            "Epoch 13/25\n",
            "3/3 [==============================] - 1s 442ms/step - loss: 0.1216 - accuracy: 0.9740\n",
            "Epoch 14/25\n",
            "3/3 [==============================] - 2s 666ms/step - loss: 0.1108 - accuracy: 0.9635\n",
            "Epoch 15/25\n",
            "3/3 [==============================] - 1s 548ms/step - loss: 0.1456 - accuracy: 0.9615\n",
            "Epoch 16/25\n",
            "3/3 [==============================] - 1s 450ms/step - loss: 0.1162 - accuracy: 0.9635\n",
            "Epoch 17/25\n",
            "3/3 [==============================] - 1s 452ms/step - loss: 0.1001 - accuracy: 0.9615\n",
            "Epoch 18/25\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0921 - accuracy: 0.9808\n",
            "Epoch 19/25\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 0.0732 - accuracy: 0.9808\n",
            "Epoch 20/25\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.0695 - accuracy: 0.9792\n",
            "Epoch 21/25\n",
            "3/3 [==============================] - 2s 477ms/step - loss: 0.0901 - accuracy: 0.9744\n",
            "Epoch 22/25\n",
            "3/3 [==============================] - 1s 458ms/step - loss: 0.0609 - accuracy: 0.9808\n",
            "Epoch 23/25\n",
            "3/3 [==============================] - 1s 458ms/step - loss: 0.0528 - accuracy: 0.9872\n",
            "Epoch 24/25\n",
            "3/3 [==============================] - 1s 459ms/step - loss: 0.0375 - accuracy: 0.9872\n",
            "Epoch 25/25\n",
            "3/3 [==============================] - 1s 443ms/step - loss: 0.0263 - accuracy: 0.9896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_acc(history):\n",
        "    acc = history.history['accuracy']\n",
        "#     val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "#     val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "#     plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "#     plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "plot_loss_acc(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "JE1fJWLoxXO1",
        "outputId": "4041ec64-92ed-460f-f8fc-55df66072d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yPnv9eto9WMn",
        "outputId": "671fb651-5be9-4ee9-b2ec-c190fdd07854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data/model/CutomCNN.h5', save_format='h5') ## We can save our model using this method."
      ],
      "metadata": {
        "id": "FgWkbskUH1Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "8TWOoAIv8hyt",
        "outputId": "cc36100e-9a1b-44e2-aacd-ac64c228ecc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-81de3d24-dc76-4dd3-a6b0-7c2ca3d4b46d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-81de3d24-dc76-4dd3-a6b0-7c2ca3d4b46d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving autumn-day-rural-garden-frame-600w-1798373137.jpeg to autumn-day-rural-garden-frame-600w-1798373137.jpeg\n",
            "User uploaded file \"autumn-day-rural-garden-frame-600w-1798373137.jpeg\" with length 68280 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DUnction for predicting Custom images.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def pred_img(img_path, img_size):\n",
        "  \n",
        "  # Load the image using PIL\n",
        "  img = Image.open(img_path)\n",
        "\n",
        "  # Resize the image to (150, 150)\n",
        "  img = img.resize(img_size)\n",
        "\n",
        "  # Convert the image to RGB format\n",
        "  img = img.convert('RGB')\n",
        "\n",
        "  # Convert the PIL image to a NumPy array\n",
        "  img_array = np.array(img)\n",
        "\n",
        "  # Reshape the array to a 4D tensor with shape (1, 150, 150, 3)\n",
        "  img_tensor = img_array.reshape((1, 150, 150, 3))\n",
        "\n",
        "  # Normalize the pixel values to be between 0 and 1\n",
        "  img_tensor = img_tensor / 255.0\n",
        "\n",
        "  # Now you can pass img_tensor to your image classification model for prediction\n",
        "  x = model.predict(img_tensor)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "FUPK7sR8xzU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_img(\"/content/drive/MyDrive/Precision Agriculture/Task1 Prep Data/autumn-day-rural-garden-frame-600w-1798373137.jpeg\", (150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O20UysT8ki1",
        "outputId": "1a94863a-7281-4297-b7e5-1a2b788dc96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 180ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9997818e-01, 3.3891627e-06, 1.8427849e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4xqX4zc98WE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}